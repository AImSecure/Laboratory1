% introduction.tex

% Section Title
\section{INTRODUCTION} \label{sec:introduction}

    This laboratory explores the implementation of a \textbf{Feed-Forward Neural Network (FFNN)} using the \textbf{CICIDS2017} dataset, a standard benchmark for intrusion detection research.  
    The goal is to construct a complete machine learning pipeline in PyTorch—from raw data preparation to model evaluation—to analyze how architectural choices and preprocessing strategies affect classification performance in cybersecurity contexts.

    \noindent The experiment unfolds through six progressive tasks that build complexity systematically. 
    Beginning with \textbf{data preprocessing}—encompassing cleaning, scaling, and outlier management—the work advances to \textbf{baseline FFNN training} using a single hidden layer architecture. 
    Subsequently, \textbf{feature bias analysis} examines the influence of specific attributes like \textit{Destination Port}, followed by \textbf{loss-function weighting} to address class imbalance challenges.
    The investigation then explores \textbf{deep network optimization} through architectural and optimizer variations, culminating in \textbf{regularization} strategies including dropout, batch normalization, and weight decay techniques.

    % \noindent The overarching aim is to understand how data characteristics and network configuration influence the model's ability to detect attack types such as \textit{DoS Hulk}, \textit{PortScan}, and \textit{Brute Force}, while maintaining robustness and generalization.
