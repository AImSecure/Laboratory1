% abstract.tex

\begin{abstract}

    % This report presents a systematic study of Feed-Forward Neural Networks (FFNNs) for multi-class network-flow classification using a curated subset of CICIDS2017. 
    % We build an end-to-end pipeline in PyTorch that encompasses data cleaning, stratified splitting, outlier inspection, and feature normalization; we then investigate how architectural depth, activation functions, batch size, optimizers, loss re-weighting, and regularization affect learning dynamics and generalization.
    % 
    % The work is organized in six tasks. First, we establish a robust preprocessing protocol and compare Standard vs. Robust scaling, ultimately adopting standardization fitted on the training split. 
    % Second, we train shallow one-hidden-layer models with different widths and show that switching from a linear activation to ReLU substantially improves minority-class recognition while preserving overall accuracy and stable convergence. 
    % Third, we expose a harmful inductive bias: the feature \emph{Destination Port} is spuriously correlated with the \emph{Brute Force} class. 
    % A simple port substitution at inference time causes a marked performance drop, and removing the feature reshapes class supports due to duplicate collapse. 
    % Fourth, we mitigate class imbalance with a class-weighted cross-entropy that improves macro-level metrics and recall for rare classes without materially harming overall accuracy. 
    % Fifth, we extend to deeper FFNNs and analyze the effect of batch size and optimizers, observing that smaller batches tend to generalize better at higher computational cost and that AdamW provides the most reliable optimization among tested choices. 
    % Finally, we assess overfitting and regularization and find that a small weight decay (AdamW) yields the best trade-off on this tabular task, whereas aggressive dropout or batch normalization can underfit or destabilize validation loss.
    % 
    % Overall, our results underline three practical lessons for intrusion-detection FFNNs on tabular features: (i) treat feature-induced biases explicitly; (ii) prefer training-set-fitted standardization and class-weighted losses when imbalance matters; and (iii) adopt modest capacity with careful regularization (light weight decay), ReLU activations, and a robust optimizer such as AdamW.

    This laboratory investigates the design and optimization of \textbf{Feed-Forward Neural Networks (FFNNs)} for \textbf{intrusion detection} using the \textbf{CICIDS2017} dataset.  
    A complete machine learning pipeline was implemented—from data cleaning and normalization to network training, regularization, and evaluation—across six incremental tasks.  
    Initial preprocessing ensured data integrity and mitigated strong feature bias, notably caused by the \texttt{Destination Port} attribute.  
    A shallow baseline model established reference performance, while the introduction of \textbf{ReLU activation} and \textbf{weighted loss functions} markedly improved the detection of minority attack classes.  
    Subsequent experiments on deeper architectures and optimizers identified a \textbf{three-layer FFNN (128-64-32)} trained with \textbf{AdamW} as the most effective configuration.  
    Regularization methods, particularly \textbf{Batch Normalization}, further enhanced stability and generalization, yielding approximately \textbf{96\% accuracy} and \textbf{0.94 macro-F1} on unseen data.  
    Overall, the study demonstrates that carefully engineered FFNNs—supported by robust preprocessing and class balancing—can achieve reliable and interpretable intrusion detection.  
    These findings highlight the importance of bias control, adaptive loss optimization, and regularization for deploying trustworthy \textbf{AI-driven Intrusion Detection Systems (IDS)} in real-world cybersecurity environments.

    % Shorter version:
    % This work presents the development of \textbf{Feed-Forward Neural Networks (FFNNs)} for \textbf{intrusion detection} using the \textbf{CICIDS2017} dataset.  
    % Through six progressive tasks, we address data cleaning, feature bias, class imbalance, architectural design, and overfitting control.  
    % The final model—a three-layer FFNN (128-64-32) with ReLU activation, AdamW optimization, and Batch Normalization—achieved \textbf{96\% accuracy} and \textbf{0.94 macro-F1}.  
    % Results highlight that bias mitigation, weighted loss optimization, and regularization are essential for reliable, generalizable \textbf{AI-based IDS} capable of detecting diverse network attacks in real-world cybersecurity contexts.

\end{abstract}
