{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AImSecure/Laboratory1/blob/main/lab/notebooks/Lab1_FFNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaRjftvSROvg"
      },
      "source": [
        "# Laboratory 1 — Feed Forward Neural Networks\n",
        "\n",
        "This notebook follows the lab brief in `resources/Lab1_FFNN.txt` and is organized into tasks:\n",
        "- Task 1: Data preprocessing (cleaning, splitting, outliers, normalization)\n",
        "- Task 2: Shallow NN (1 layer), train sizes {32, 64, 128}, metrics and analysis; then ReLU change\n",
        "- Task 3: Impact of specific features (Destination Port), bias test and port removal\n",
        "- Task 4: Loss function impact (weighted CrossEntropy)\n",
        "- Task 5: Deep NN, batch size, optimizer comparisons\n",
        "- Task 6: Overfitting and regularization (dropout, batchnorm, weight decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "NXfnBkl-P0ma"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svE8FspeRPW3",
        "outputId": "5300cd3c-cdb5-4617-a379-2c26e6556cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n"
          ]
        }
      ],
      "source": [
        "# --- Check Python & pip versions ---\n",
        "!python --version\n",
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyfyzIzWbHTG",
        "outputId": "052242cb-6bd8-4d1a-8165-4bd6fbb14362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "# --- Install required libraries ---\n",
        "!pip install torch\n",
        "!pip install numpy pandas scikit-learn matplotlib seaborn\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vZXgjER_TsGp"
      },
      "outputs": [],
      "source": [
        "# --- Import libraries ---\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w201oyWVxE9k"
      },
      "source": [
        "### Colab Pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kIggYNUxFuZ",
        "outputId": "cb60c7f8-966f-460b-d4ce-d9ea1e9bf06b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# --- Check GPU availability ---\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH-w_NELxHpV",
        "outputId": "8f4b0da8-0fd5-4fcf-b585-5f008a09dc6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ],
      "source": [
        "# --- Check RAM availability ---\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rFNp6fgTv9w"
      },
      "source": [
        "### Paths setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAnAndzpTxe5",
        "outputId": "fdb14711-076b-4d9d-bdf1-e2ce81e45304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive (for Google Colab users) ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqMS_38yTvFN",
        "outputId": "789f6341-9aa7-420c-f667-7df8657aebaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project path: /content/drive/MyDrive/Projects/AImSecure/Laboratory1/\n",
            "Data path: /content/drive/MyDrive/Projects/AImSecure/Laboratory1/data/\n",
            "Results path: /content/drive/MyDrive/Projects/AImSecure/Laboratory1/results/\n"
          ]
        }
      ],
      "source": [
        "# --- Define Paths ---\n",
        "group = 'AImSecure'\n",
        "laboratory = 'Laboratory1'\n",
        "\n",
        "base_path = '/content/drive/MyDrive/'\n",
        "project_path = base_path + f'Projects/{group}/{laboratory}/'\n",
        "data_path = project_path + 'data/'\n",
        "results_path = project_path + 'results/'\n",
        "\n",
        "# --- Ensure directories exist ---\n",
        "os.makedirs(project_path, exist_ok=True)\n",
        "os.makedirs(data_path, exist_ok=True)\n",
        "os.makedirs(results_path, exist_ok=True)\n",
        "\n",
        "print(f\"Project path: {project_path}\")\n",
        "print(f\"Data path: {data_path}\")\n",
        "print(f\"Results path: {results_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pi-G9FFHwZjK"
      },
      "outputs": [],
      "source": [
        "# --- Set visual style ---\n",
        "sns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.1)\n",
        "\n",
        "def save_plot(fig: plt.Figure, filename: str, path: str = \"./plots/\", fmt: str = \"png\", dpi: int = 300) -> None:\n",
        "    \"\"\"\n",
        "    Save a Matplotlib figure in a specific to a specified directory.\n",
        "\n",
        "    Args:\n",
        "        fig (plt.Figure): Matplotlib figure object to save.\n",
        "        filename (str): Name of the file to save (e.g., 'plot.png').\n",
        "        path (str, optional): Directory path to save the figure. Defaults to './plots/'.\n",
        "        fmt (str, optional): File format for the saved figure. Defaults to 'png'.\n",
        "        dpi (int, optional): Dots per inch for the saved figure. Defaults to 300.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Ensure the directory exists\n",
        "    os.makedirs(path, exist_ok=True)\n",
        "    save_path = os.path.join(path, f\"{filename}.{fmt}\")\n",
        "\n",
        "    # Save the figure\n",
        "    fig.savefig(save_path, bbox_inches='tight', pad_inches=0.1, dpi=dpi, format=fmt)\n",
        "    # plt.close(fig) # Removed to display plots in notebook\n",
        "\n",
        "    print(f\"Saved plot: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dswv2Je3UA5Y"
      },
      "source": [
        "## Task 1 — Data preprocessing\n",
        "What we will do:\n",
        "- Load CSV from `lab/data/dataset_lab_1.csv`\n",
        "- Inspect basic info, class distribution, and feature ranges\n",
        "- Remove NaN and duplicate rows; report counts before/after\n",
        "- Split into train/val/test with stratify (60/20/20, fixed SEED)\n",
        "- Inspect outliers on train/val (e.g., boxplots, z-scores) and choose normalization\n",
        "- Fit scaler on train only; transform val/test; persist scaler if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vEJrc85UCuJ",
        "outputId": "36e6b75d-4f78-4d80-ad89-5d36a65228bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape (raw): (31507, 17)\n",
            "Columns: ['Flow Duration', 'Flow IAT Mean', 'Fwd PSH Flags', 'Bwd Packet Length Mean', 'Bwd Packet Length Max', 'Flow Bytes/s', 'Down/Up Ratio', 'SYN Flag Count', 'Fwd Packet Length Mean', 'Fwd IAT Std', 'Packet Length Mean', 'Fwd Packet Length Max', 'Subflow Fwd Packets', 'Flow Packets/s', 'Total Fwd Packets', 'Destination Port', 'Label']\n",
            "   Flow Duration  Flow IAT Mean  Fwd PSH Flags  Bwd Packet Length Mean  \\\n",
            "0         303376        30337.6              0                   749.4   \n",
            "1            117          117.0              0                     0.0   \n",
            "2            142          142.0              0                     0.0   \n",
            "\n",
            "   Bwd Packet Length Max  Flow Bytes/s  Down/Up Ratio  SYN Flag Count  \\\n",
            "0                   1448     12743.263              0               0   \n",
            "1                      0         0.000              1               0   \n",
            "2                      0     84507.040              0               0   \n",
            "\n",
            "   Fwd Packet Length Mean  Fwd IAT Std  Packet Length Mean  \\\n",
            "0               19.833334     98776.15           322.16666   \n",
            "1                0.000000         0.00             0.00000   \n",
            "2                6.000000         0.00             6.00000   \n",
            "\n",
            "   Fwd Packet Length Max  Subflow Fwd Packets  Flow Packets/s  \\\n",
            "0                    119                    6       36.258636   \n",
            "1                      0                    1    17094.018000   \n",
            "2                      6                    2    14084.507000   \n",
            "\n",
            "   Total Fwd Packets  Destination Port   Label  \n",
            "0                  6               443  Benign  \n",
            "1                  1             52631  Benign  \n",
            "2                  2                80  Benign  \n",
            "\n",
            "Label distribution (raw):\n",
            "Label\n",
            "Benign         20000\n",
            "DoS Hulk        5000\n",
            "PortScan        5000\n",
            "Brute Force     1507\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# --- Load dataset and perform initial inspection ---\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create directory for plots\n",
        "save_dir = results_path + 'images/' + 'task1_plots/'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Load Dataset\n",
        "file_path = data_path + 'dataset_lab_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Shape (raw):\", df.shape)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "print(df.head(3))\n",
        "\n",
        "# Basic info\n",
        "print(\"\\nLabel distribution (raw):\")\n",
        "print(df['Label'].value_counts(dropna=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2aKPJf9UwZjL"
      },
      "outputs": [],
      "source": [
        "def plot_class_distribution(\n",
        "    df,\n",
        "    label_col='Label',\n",
        "    save_path='./plots/',\n",
        "    fig_size=(8, 5),\n",
        "    color='Set2'\n",
        "):\n",
        "    \"\"\"\n",
        "    Plot the number of samples for each class.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "        label_col (str): The name of the label column. Defaults to 'Label'.\n",
        "        save_path (str): The directory to save the plot. Defaults to './plots/'.\n",
        "        fig_size (tuple): Size of the figure. Defaults to (8, 5).\n",
        "        color (str): Seaborn color.\n",
        "    \"\"\"\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # Create a figure and axes for the plot\n",
        "    fig, ax = plt.subplots(figsize=fig_size)\n",
        "\n",
        "    # Create a countplot showing the distribution of classes\n",
        "    sns.countplot(x=label_col, data=df, order=df[label_col].value_counts().index, ax=ax, color='skyblue')\n",
        "\n",
        "    # Set the title and labels for the plot\n",
        "    ax.set_title(\"Class Distribution\")\n",
        "    ax.set_xlabel(\"Traffic Type\")\n",
        "    ax.set_ylabel(\"Count\")\n",
        "\n",
        "    # Rotate x-axis labels for better readability\n",
        "    plt.xticks(rotation=30)\n",
        "\n",
        "    # Annotate bars with counts\n",
        "    for p in ax.patches:\n",
        "        height = p.get_height()\n",
        "        ax.annotate(f'{height}', (p.get_x() + p.get_width() / 2., height),\n",
        "                    ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "    # Save the plot to the specified path\n",
        "    save_plot(fig, \"class_distribution\", save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "Lpu-3ls8hlRV",
        "outputId": "a6d307a1-195b-4fbd-d539-6c3de48d185a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved plot: /content/drive/MyDrive/Projects/AImSecure/Laboratory1/results/images/task1_plots/class_distribution.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# --- Visualize raw data characteristics and distributions ---\n",
        "\n",
        "# Plot class distribution to understand data balance\n",
        "plot_class_distribution(df, save_path=save_dir)\n",
        "\n",
        "# TODO: check for other useful plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owZLKx9LeWOj"
      },
      "source": [
        "### Removing NaN and duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk16WOa3hlHh",
        "outputId": "028c7f21-0a10-498e-8183-f770d04c266e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removed 2114 rows (NaN+dupes). New shape: (29393, 17)\n"
          ]
        }
      ],
      "source": [
        "# --- Remove NaN and duplicates ---\n",
        "\n",
        "raw_n = len(df)\n",
        "df = df.dropna()\n",
        "df = df.drop_duplicates()\n",
        "clean_n = len(df)\n",
        "\n",
        "print(f\"Removed {raw_n-clean_n} rows (NaN+dupes). New shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nLabel distribution (after NaN and duplicates removal):\")\n",
        "print(df['Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FVlanNCbVbe",
        "outputId": "0becd9fe-9ab8-4714-a101-6392b4b93b16"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Label distribution (after NaN and duplicates removal):\n",
            "Label\n",
            "Benign         19248\n",
            "PortScan        4850\n",
            "DoS Hulk        3868\n",
            "Brute Force     1427\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSgqScEihOaM"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCMaPIGOhKpE",
        "outputId": "8e3b3b6f-7d2d-4426-8216-dd1ad659556f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splits: (17635, 16) (5879, 16) (5879, 16)\n",
            "Train label counts:\n",
            " Label\n",
            "Benign         11548\n",
            "PortScan        2910\n",
            "DoS Hulk        2321\n",
            "Brute Force      856\n",
            "Name: count, dtype: int64\n",
            "Val label counts:\n",
            " Label\n",
            "Benign         3850\n",
            "PortScan        970\n",
            "DoS Hulk        774\n",
            "Brute Force     285\n",
            "Name: count, dtype: int64\n",
            "Test label counts:\n",
            " Label\n",
            "Benign         3850\n",
            "PortScan        970\n",
            "DoS Hulk        773\n",
            "Brute Force     286\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# --- Split data ---\n",
        "\n",
        "# Split features/target\n",
        "label_col = 'Label'\n",
        "feature_cols = [c for c in df.columns if c != label_col]\n",
        "X = df[feature_cols]\n",
        "y = df[label_col]\n",
        "\n",
        "# We use a stratified approach due to the class imbalance\n",
        "\n",
        "# Train/val/test split 60/20/20 with stratify\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
        "    X, y, test_size=0.4, stratify=y, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42\n",
        ")\n",
        "print(\"Splits:\", X_train.shape, X_val.shape, X_test.shape)\n",
        "print(\"Train label counts:\\n\", y_train.value_counts())\n",
        "print(\"Val label counts:\\n\", y_val.value_counts())\n",
        "print(\"Test label counts:\\n\", y_test.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalize data and handle outliers"
      ],
      "metadata": {
        "id": "fnab_F5ah49P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to firstly visualize some outliers\n"
      ],
      "metadata": {
        "id": "FmQUfXEbh0jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Apply normalization with outlier handling ---\n",
        "\n",
        "# TODO: check and update this block\n",
        "\n",
        "# Outlier analysis: count features with z-score > 3 on training set\n",
        "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "zs = ((X_train[num_cols] - X_train[num_cols].mean())/X_train[num_cols].std(ddof=0)).abs()\n",
        "outlier_counts = (zs > 3).sum().sort_values(ascending=False)\n",
        "print(\"\\nOutliers (>3 std) per feature on train:\\n\", outlier_counts.head(10))\n",
        "\n",
        "# Handle infinite values by replacing with NaN\n",
        "X_train[num_cols] = X_train[num_cols].replace([np.inf, -np.inf], np.nan)\n",
        "X_val[num_cols] = X_val[num_cols].replace([np.inf, -np.inf], np.nan)\n",
        "X_test[num_cols] = X_test[num_cols].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Impute missing values using median strategy fitted on training data\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train_imputed = imputer.fit_transform(X_train[num_cols])\n",
        "X_val_imputed = imputer.transform(X_val[num_cols])\n",
        "X_test_imputed = imputer.transform(X_test[num_cols])\n",
        "\n",
        "# Standardize features using StandardScaler fitted on training data only\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train_imputed)\n",
        "X_val_s = scaler.transform(X_val_imputed)\n",
        "X_test_s = scaler.transform(X_test_imputed)\n",
        "\n",
        "# --- Save preprocessing metadata for reproducibility ---\n",
        "\n",
        "scaler_meta = {\n",
        "    \"type\":\"StandardScaler\",\n",
        "    \"fit_on\":\"train\",\n",
        "    \"num_features\": num_cols,\n",
        "    \"imputer_strategy\": \"median\"\n",
        "}\n",
        "\n",
        "# Create metrics_dir if it doesn't exist\n",
        "metrics_dir = results_path + 'metrics/'\n",
        "os.makedirs(metrics_dir, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(metrics_dir, \"scaler_meta.json\"), \"w\") as f:\n",
        "    json.dump(scaler_meta, f, indent=2)\n",
        "\n",
        "print(\"Normalization complete. Shapes:\", X_train_s.shape, X_val_s.shape, X_test_s.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8axCj9fXIRk",
        "outputId": "7a0b3d81-fb43-493d-f622-3a509fee34b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Outliers (>3 std) per feature on train:\n",
            " Fwd PSH Flags             710\n",
            "SYN Flag Count            710\n",
            "Fwd IAT Std               570\n",
            "Bwd Packet Length Max     523\n",
            "Bwd Packet Length Mean    340\n",
            "Packet Length Mean        274\n",
            "Destination Port          231\n",
            "Fwd Packet Length Max     204\n",
            "Flow IAT Mean             196\n",
            "Fwd Packet Length Mean    153\n",
            "dtype: int64\n",
            "Normalization complete. Shapes: (17635, 16) (5879, 16) (5879, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuUQ3CLrwZjL"
      },
      "outputs": [],
      "source": [
        "def plot_boxplots(df, numeric_cols=None, save_path='./plots/'):\n",
        "    \"\"\"\n",
        "    Create boxplots for each numeric feature to detect outliers.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "        numeric_cols (list): A list of numeric column names to plot. If None, plots all numeric columns.\n",
        "        save_path (str): The directory to save the plot. Defaults to './plots/'.\n",
        "    \"\"\"\n",
        "    # If numeric_cols is not provided, select all numeric columns\n",
        "    if numeric_cols is None:\n",
        "        numeric_cols = df.select_dtypes(include=np.number).columns\n",
        "\n",
        "    # Iterate through each numeric column and plot a boxplot\n",
        "    for col in numeric_cols:\n",
        "        # Create a figure and axes for the plot\n",
        "        fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "        # Create a boxplot\n",
        "        sns.boxplot(x=df[col], color='lightcoral', ax=ax)\n",
        "\n",
        "        # Set the title for the boxplot\n",
        "        ax.set_title(f\"Boxplot of {col}\")\n",
        "\n",
        "        # Replace '/' with '_' in filename to avoid path issues\n",
        "        filename = f\"boxplot_{col.replace('/', '_')}\"\n",
        "\n",
        "        # Save the plot to the specified path\n",
        "        save_plot(fig, filename, save_path)\n",
        "\n",
        "\n",
        "def plot_boxplots_by_class(df, features, label_col='Label', save_path='./plots/'):\n",
        "    \"\"\"\n",
        "    Create boxplots for specific features grouped by class.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): The input DataFrame.\n",
        "        features (list): A list of feature names to plot.\n",
        "        label_col (str): The name of the label column. Defaults to 'Label'.\n",
        "        save_path (str): The directory to save the plot. Defaults to './plots/'.\n",
        "    \"\"\"\n",
        "    # Iterate through each feature and plot a boxplot grouped by class\n",
        "    for col in features:\n",
        "        # Create a figure and axes for the plot\n",
        "        fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "        # Create a boxplot grouped by class\n",
        "        sns.boxplot(x=label_col, y=col, data=df, ax=ax)\n",
        "\n",
        "        # Rotate x-axis labels for better readability\n",
        "        plt.xticks(rotation=30)\n",
        "\n",
        "        # Set the title for the boxplot\n",
        "        ax.set_title(f\"Boxplot of {col} by Class\")\n",
        "\n",
        "        # Replace '/' with '_' in filename to avoid path issues\n",
        "        filename = f\"boxplot_by_class_{col.replace('/', '_')}\"\n",
        "\n",
        "        # Save the plot to the specified path\n",
        "        save_plot(fig, filename, save_path)\n",
        "\n",
        "\n",
        "def plot_pca_2d(X, y, save_path='./plots/'):\n",
        "    \"\"\"\n",
        "    Perform PCA and plot the first two components colored by class.\n",
        "\n",
        "    Args:\n",
        "        X (pd.DataFrame or np.ndarray): The input features.\n",
        "        y (pd.Series or np.ndarray): The target labels.\n",
        "        save_path (str): The directory to save the plot. Defaults to './plots/'.\n",
        "    \"\"\"\n",
        "    # Standardize the data before applying PCA\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Apply PCA to reduce dimensions to 2\n",
        "    pca = PCA(n_components=2)\n",
        "    X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "    # Create a DataFrame for plotting\n",
        "    df_pca = pd.DataFrame({\n",
        "        'PC1': X_pca[:, 0],\n",
        "        'PC2': X_pca[:, 1],\n",
        "        'Label': y.values if isinstance(y, pd.Series) else y\n",
        "    })\n",
        "\n",
        "    # Create a scatter plot of the first two principal components\n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='Label', palette='tab10', s=50, alpha=0.7)\n",
        "\n",
        "    # Set the title for the plot\n",
        "    ax.set_title(\"PCA 2D Projection\")\n",
        "\n",
        "    # Save the plot to the specified path\n",
        "    save_plot(fig, \"pca_2d_projection\", save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoZs0GEUeZ5Z"
      },
      "outputs": [],
      "source": [
        "# --- Generate visualization plots for outlier analysis and dimensionality reduction ---\n",
        "\n",
        "# TODO: check and update this block\n",
        "# TODO: remove functions that are not needed\n",
        "\n",
        "# Create boxplots for top numeric features\n",
        "#plot_boxplots(df, numeric_cols=numeric_features, save_path=save_dir) % FIXME: check also the function\n",
        "top_features = numeric_features[:5]\n",
        "#plot_boxplots_by_class(df, features=top_features, save_path=save_dir) % FIXME: check also the function\n",
        "\n",
        "# Prepare clean dataset for PCA visualization\n",
        "df_cleaned = df.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Impute missing values before PCA (fit imputer on full cleaned dataset)\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df_cleaned[numeric_features] = imputer.fit_transform(df_cleaned[numeric_features])\n",
        "\n",
        "# Generate PCA 2D projection to visualize class separation\n",
        "#plot_pca_2d(X=df_cleaned[numeric_features], y=df_cleaned['Label'], save_path=save_dir) % FIXME: check also the function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsY0Xe28wZjM"
      },
      "outputs": [],
      "source": [
        "def plot_boxplots_before_after(X_before, X_after, feature_names=None, save_path='./plots/'):\n",
        "    \"\"\"\n",
        "    Compare feature distributions before and after normalization using boxplots.\n",
        "    \"\"\"\n",
        "    # Use generic feature names if none are provided\n",
        "    if feature_names is None:\n",
        "        feature_names = [f'Feature_{i}' for i in range(X_before.shape[1])]\n",
        "\n",
        "    # Create DataFrames from the input arrays for easier plotting\n",
        "    df_before = pd.DataFrame(X_before, columns=feature_names)\n",
        "    df_after = pd.DataFrame(X_after, columns=feature_names)\n",
        "\n",
        "    # Iterate through each feature and create a comparison boxplot\n",
        "    for col in feature_names:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "        # Boxplot for the data before normalization\n",
        "        sns.boxplot(y=df_before[col], ax=axes[0], color='lightgray')\n",
        "\n",
        "        # Boxplot for the data after normalization\n",
        "        sns.boxplot(y=df_after[col], ax=axes[1], color='lightblue')\n",
        "\n",
        "        # Set titles for the subplots\n",
        "        axes[0].set_title(f\"{col} (Before)\")\n",
        "        axes[1].set_title(f\"{col} (After)\")\n",
        "\n",
        "        # Set a main title for the figure\n",
        "        plt.suptitle(f\"Boxplot Comparison — {col}\")\n",
        "\n",
        "        # Replace '/' with '_' in filename to avoid path issues\n",
        "        filename = f\"boxplot_norm_comparison_{col.replace('/', '_')}\"\n",
        "\n",
        "        # Save the plot\n",
        "        save_plot(fig, filename, save_path)\n",
        "\n",
        "\n",
        "def plot_histograms_before_after(X_before, X_after, feature_names=None, bins=30, save_path='./plots/'):\n",
        "    \"\"\"\n",
        "    Compare feature histograms before and after normalization.\n",
        "    \"\"\"\n",
        "    # Use generic feature names if none are provided\n",
        "    if feature_names is None:\n",
        "        feature_names = [f'Feature_{i}' for i in range(X_before.shape[1])]\n",
        "\n",
        "    # Create DataFrames from the input arrays for easier plotting\n",
        "    df_before = pd.DataFrame(X_before, columns=feature_names)\n",
        "    df_after = pd.DataFrame(X_after, columns=feature_names)\n",
        "\n",
        "    # Iterate through each feature and create a comparison histogram\n",
        "    for col in feature_names:\n",
        "        fig, ax = plt.subplots(figsize=(6, 4))\n",
        "\n",
        "        # Histogram for the data before normalization\n",
        "        sns.histplot(df_before[col], bins=bins, color='red', label='Before', kde=True, stat=\"density\")\n",
        "\n",
        "        # Histogram for the data after normalization\n",
        "        sns.histplot(df_after[col], bins=bins, color='blue', label='After', kde=True, stat=\"density\")\n",
        "\n",
        "        # Set the title for the histogram\n",
        "        ax.set_title(f\"Histogram Comparison — {col}\")\n",
        "\n",
        "        # Add a legend to distinguish between before and after\n",
        "        ax.legend()\n",
        "\n",
        "        # Replace '/' with '_' in filename to avoid path issues\n",
        "        filename = f\"hist_norm_comparison_{col.replace('/', '_')}\"\n",
        "\n",
        "        # Save the plot\n",
        "        save_plot(fig, filename, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wScvBxa2wZjM"
      },
      "outputs": [],
      "source": [
        "# --- Compare feature distributions before and after normalization ---\n",
        "\n",
        "# TODO: check and update this block\n",
        "# TODO: remove functions that are not needed\n",
        "\n",
        "# Generate comparison plots showing normalization effect\n",
        "#plot_boxplots_before_after(X_train, X_train_s, feature_names=numeric_features, save_path=save_dir) % FIXME: check also the function\n",
        "#plot_histograms_before_after(X_train, X_train_s, feature_names=numeric_features, save_path=save_dir) % FIXME: check also the function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QJSBi_iRPxw"
      },
      "source": [
        "## PyTorch datasets and loaders\n",
        "We convert standardized NumPy arrays to tensors and build dataloaders with a configurable batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEMXF-uXbHTI"
      },
      "outputs": [],
      "source": [
        "# Label encoding\n",
        "classes = sorted(pd.unique(y))\n",
        "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
        "y_train_i = y_train.map(class_to_idx).to_numpy()\n",
        "y_val_i = y_val.map(class_to_idx).to_numpy()\n",
        "y_test_i = y_test.map(class_to_idx).to_numpy()\n",
        "\n",
        "# Tensors\n",
        "X_train_t = torch.tensor(X_train_s, dtype=torch.float32)\n",
        "X_val_t   = torch.tensor(X_val_s,   dtype=torch.float32)\n",
        "X_test_t  = torch.tensor(X_test_s,  dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train_i, dtype=torch.long)\n",
        "y_val_t   = torch.tensor(y_val_i,   dtype=torch.long)\n",
        "y_test_t  = torch.tensor(y_test_i,  dtype=torch.long)\n",
        "\n",
        "INPUT_DIM = X_train_t.shape[1]\n",
        "NUM_CLASSES = len(classes)\n",
        "print(\"Input dim:\", INPUT_DIM, \"Classes:\", NUM_CLASSES, classes)\n",
        "\n",
        "# Dataloaders\n",
        "BATCH_SIZE = 64\n",
        "train_ds = TensorDataset(X_train_t, y_train_t)\n",
        "val_ds   = TensorDataset(X_val_t, y_val_t)\n",
        "test_ds  = TensorDataset(X_test_t, y_test_t)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hIyPgwBbHTI"
      },
      "source": [
        "## Training utilities\n",
        "Helper functions: training loop with early stopping, evaluation, and plotting loss curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kL2RavXfbHTI"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion=None):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        if criterion is not None:\n",
        "            total_loss += criterion(logits, yb).item() * xb.size(0)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_targets.append(yb.cpu().numpy())\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "    avg_loss = (total_loss / len(loader.dataset)) if criterion is not None else None\n",
        "    return avg_loss, all_preds, all_targets\n",
        "\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience=10, mode='min'):\n",
        "        self.patience = patience\n",
        "        self.mode = mode\n",
        "        self.best = None\n",
        "        self.count = 0\n",
        "    def step(self, metric):\n",
        "        if self.best is None:\n",
        "            self.best = metric\n",
        "            return False\n",
        "        improve = metric < self.best if self.mode == 'min' else metric > self.best\n",
        "        if improve:\n",
        "            self.best = metric\n",
        "            self.count = 0\n",
        "            return False\n",
        "        else:\n",
        "            self.count += 1\n",
        "            return self.count >= self.patience\n",
        "\n",
        "def plot_losses(train_losses, val_losses, title, save_path=None):\n",
        "    fig, ax = plt.subplots(figsize=(6,4))\n",
        "    ax.plot(train_losses, label='train')\n",
        "    ax.plot(val_losses, label='val')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_title(title)\n",
        "    ax.legend()\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        save_plot_to_drive(fig, Path(save_path).name, Path(save_path).parent)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZQQDEOsbHTI"
      },
      "source": [
        "## Task 2 — Shallow Neural Network (1 layer)\n",
        "We will:\n",
        "- Define a single-hidden-layer FFNN with hidden sizes h in {32, 64, 128}\n",
        "- Use Linear activation as requested (i.e., no nonlinearity) for the first run\n",
        "- Train with AdamW, lr=5e-4, batch=64, CE loss, up to 100 epochs with early stopping\n",
        "- Plot train/val losses, select best by lowest val loss, report validation classification\n",
        "- Evaluate best on test and compare to validation\n",
        "- Then change activation to ReLU for the best width and retrain; discuss change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVg9iDIHbHTJ"
      },
      "source": [
        "### ReLU variant for the best width\n",
        "Train the same architecture but with ReLU activation, then compare validation report to the linear version. Do NOT test-compare unless justified (overfitting risk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vmSbNK-bHTJ"
      },
      "outputs": [],
      "source": [
        "# Train ReLU variant for the best width\n",
        "best_h = best['h']\n",
        "relu_tag = f\"shallow_relu_h{best_h}\"\n",
        "model_relu = ShallowFFNN(INPUT_DIM, best_h, NUM_CLASSES, activation='relu')\n",
        "model_relu, tr_r, va_r = train_model(model_relu, train_loader, val_loader, epochs=100, lr=5e-4, patience=10, tag=relu_tag)\n",
        "va_loss_r, va_preds_r, va_tgts_r = evaluate(model_relu, val_loader, nn.CrossEntropyLoss())\n",
        "print(\"Validation report (ReLU, best width)\")\n",
        "print(classification_report(va_tgts_r, va_preds_r, target_names=classes))\n",
        "print(\"Note: Comparing on test at this stage may be misleading; validate design choices first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wYU39f7bHTJ"
      },
      "source": [
        "## Task 3 — Impact of specific features (Destination Port)\n",
        "Steps:\n",
        "1) Modify only the test split: for rows with Label==Brute Force and Destination Port==80, change to 8080. Re-run inference with the best model and compare test metrics to validation baseline.\n",
        "2) Remove the Destination Port feature entirely from the original dataset; redo preprocessing (cleaning, split, scaling); report PortScan counts before/after duplicates removal; discuss class balance.\n",
        "Note: Keep a copy of the original splits to ensure fair comparisons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TsIfOJNbHTJ"
      },
      "outputs": [],
      "source": [
        "# 3.1: Modify Destination Port for Brute Force in Test and re-evaluate\n",
        "if 'Destination Port' in feature_cols:\n",
        "    # Build a modifiable DataFrame for test\n",
        "    test_df = X_test.copy()\n",
        "    test_df['Label'] = y_test.values\n",
        "    before_counts = (test_df[(test_df['Label']=='Brute Force') & (test_df['Destination Port']==80)].shape[0])\n",
        "    # Change 80 -> 8080 for Brute Force\n",
        "    mask = (test_df['Label']=='Brute Force') & (test_df['Destination Port']==80)\n",
        "    test_df.loc[mask, 'Destination Port'] = 8080\n",
        "    after_counts = (test_df[(test_df['Label']=='Brute Force') & (test_df['Destination Port']==80)].shape[0])\n",
        "    print(f\"Changed Brute Force port 80 -> 8080 in test: {before_counts} rows affected, now {after_counts} with port==80\")\n",
        "\n",
        "    # Re-standardize using the SAME scaler (train fit)\n",
        "    test_df_std = scaler.transform(test_df[num_cols])\n",
        "    X_test_mod_t = torch.tensor(test_df_std, dtype=torch.float32)\n",
        "    y_test_mod_t = torch.tensor(y_test_i, dtype=torch.long)\n",
        "    test_mod_loader = DataLoader(TensorDataset(X_test_mod_t, y_test_mod_t), batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Inference with the best validation model (from Task 2)\n",
        "    mod_loss, mod_preds, mod_tgts = evaluate(best_model, test_mod_loader, nn.CrossEntropyLoss())\n",
        "    print(\"Modified test loss:\", round(mod_loss, 4))\n",
        "    print(classification_report(mod_tgts, mod_preds, target_names=classes))\n",
        "else:\n",
        "    print(\"Destination Port feature not found; skip part 3.1.\")\n",
        "\n",
        "# 3.2: Remove Destination Port from the original dataset and redo preprocessing\n",
        "if 'Destination Port' in feature_cols:\n",
        "    noport_df = df.drop(columns=['Destination Port'])\n",
        "    print(\"Shape without Destination Port:\", noport_df.shape)\n",
        "    # Remove duplicates specifically and count PortScan before/after\n",
        "    portscan_before = df[df['Label']=='PortScan'].shape[0]\n",
        "    noport_df_nodup = noport_df.drop_duplicates()\n",
        "    labels_noport = noport_df_nodup['Label']\n",
        "    portscan_after = noport_df_nodup[labels_noport=='PortScan'].shape[0]\n",
        "    print(f\"PortScan count before: {portscan_before}, after dropping duplicates (no port): {portscan_after}\")\n",
        "    print(\"Class balance (no port, after dedupe):\\n\", labels_noport.value_counts())\n",
        "else:\n",
        "    print(\"Destination Port feature not present; already removed earlier.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5vpgTO5bHTJ"
      },
      "source": [
        "## Task 4 — Impact of Loss Function (class weighting)\n",
        "- Compute class weights from the training partition only, using sklearn `compute_class_weight(class_weight='balanced')`\n",
        "- Retrain the best architecture (from Task 2 or after port removal, depending on stage)\n",
        "- Compare per-class metrics, accuracy, and F1 against unweighted run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjUSZpsPbHTJ"
      },
      "outputs": [],
      "source": [
        "# Compute class weights from TRAIN partition\n",
        "classes_arr = np.array(classes)\n",
        "weights = compute_class_weight(class_weight='balanced', classes=classes_arr, y=y_train.values)\n",
        "print(\"Class weights (train):\", dict(zip(classes, np.round(weights,3))))\n",
        "\n",
        "# Map weights to class index order 0..NUM_CLASSES-1\n",
        "weight_vec = np.array([weights[list(classes_arr).index(c)] for c in classes])\n",
        "\n",
        "# Retrain best shallow width with weights (use ReLU variant for stronger baseline)\n",
        "weighted_tag = f\"shallow_weighted_h{best_h}\"\n",
        "weighted_model = ShallowFFNN(INPUT_DIM, best_h, NUM_CLASSES, activation='relu')\n",
        "weighted_model, tr_w, va_w = train_model(\n",
        "    weighted_model, train_loader, val_loader, epochs=100, lr=5e-4, patience=10, tag=weighted_tag,\n",
        "    weight=weight_vec\n",
        ")\n",
        "va_loss_w, va_preds_w, va_tgts_w = evaluate(weighted_model, val_loader, nn.CrossEntropyLoss())\n",
        "print(\"Validation (weighted):\")\n",
        "print(classification_report(va_tgts_w, va_preds_w, target_names=classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8lrIiG6bHTK"
      },
      "source": [
        "## Task 5 — Deep Neural Networks, Batch Size, Optimizers\n",
        "We will:\n",
        "- Try depths L in {3, 4, 5} and for each try 2 hidden-size patterns (total 6)\n",
        "- Use ReLU, AdamW, lr=5e-4, epochs<=50 with early stopping\n",
        "- Select best by validation; evaluate best on test\n",
        "- Compare batch sizes {4, 64, 256, 1024} on best arch: report validation metrics and wall-clock time\n",
        "- Compare optimizers: SGD, SGD+Momentum (0.1, 0.5, 0.9), AdamW; analyze losses and times; then tune LR/epochs for the best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8FOzAnKbHTK"
      },
      "outputs": [],
      "source": [
        "class DeepFFNN(nn.Module):\n",
        "    def __init__(self, input_dim, layers, num_classes):\n",
        "        super().__init__()\n",
        "        dims = [input_dim] + layers\n",
        "        mods = []\n",
        "        for i in range(len(dims)-1):\n",
        "            mods.append(nn.Linear(dims[i], dims[i+1]))\n",
        "            mods.append(nn.ReLU())\n",
        "        mods.append(nn.Linear(dims[-1], num_classes))\n",
        "        self.net = nn.Sequential(*mods)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Architectures to try: two per depth 3,4,5\n",
        "arch_grid = {\n",
        "    3: [[32,16,8],[64,32,16]],\n",
        "    4: [[64,32,16,8],[32,32,16,8]],\n",
        "    5: [[128,64,32,16,8],[32,32,32,16,8]],\n",
        "}\n",
        "\n",
        "arch_results = []\n",
        "for depth, patterns in arch_grid.items():\n",
        "    for pattern in patterns:\n",
        "        tag = f\"deep_L{depth}_h{'-'.join(map(str,pattern))}\"\n",
        "        model = DeepFFNN(INPUT_DIM, pattern, NUM_CLASSES)\n",
        "        model, tr_d, va_d = train_model(model, train_loader, val_loader, epochs=50, lr=5e-4, patience=8, tag=tag)\n",
        "        va_loss_d, va_preds_d, va_tgts_d = evaluate(model, val_loader, nn.CrossEntropyLoss())\n",
        "        rep_d = classification_report(va_tgts_d, va_preds_d, target_names=classes, output_dict=True)\n",
        "        arch_results.append({\"depth\":depth, \"pattern\":pattern, \"val_loss\":va_loss_d, \"report\":rep_d, \"model\":model, \"tag\":tag})\n",
        "\n",
        "best_deep = min(arch_results, key=lambda r: r['val_loss'])\n",
        "print(\"Best deep arch:\", best_deep['pattern'], \"(L=\", len(best_deep['pattern']), \") val_loss=\", round(best_deep['val_loss'],4))\n",
        "\n",
        "# Evaluate best deep on test\n",
        "best_deep_model = best_deep['model']\n",
        "loss_td, preds_td, tgts_td = evaluate(best_deep_model, test_loader, nn.CrossEntropyLoss())\n",
        "print(\"Test report (best deep):\")\n",
        "print(classification_report(tgts_td, preds_td, target_names=classes))\n",
        "\n",
        "# Batch size experiment\n",
        "for bs in [4, 64, 256, 1024]:\n",
        "    tl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
        "    vl = DataLoader(val_ds, batch_size=bs)\n",
        "    model = DeepFFNN(INPUT_DIM, best_deep['pattern'], NUM_CLASSES)\n",
        "    start = time.time()\n",
        "    model, tr_b, va_b = train_model(model, tl, vl, epochs=50, lr=5e-4, patience=8, tag=f\"deep_bs{bs}\")\n",
        "    elapsed = time.time()-start\n",
        "    va_loss_b, va_preds_b, va_tgts_b = evaluate(model, vl, nn.CrossEntropyLoss())\n",
        "    print(f\"BS={bs}: val_loss={va_loss_b:.4f}, time={elapsed:.1f}s\")\n",
        "\n",
        "# Optimizer experiment\n",
        "optims = [\n",
        "    (\"SGD\", lambda params: optim.SGD(params, lr=5e-3)),\n",
        "    (\"SGD_m0.1\", lambda params: optim.SGD(params, lr=5e-3, momentum=0.1)),\n",
        "    (\"SGD_m0.5\", lambda params: optim.SGD(params, lr=5e-3, momentum=0.5)),\n",
        "    (\"SGD_m0.9\", lambda params: optim.SGD(params, lr=5e-3, momentum=0.9)),\n",
        "    (\"AdamW\", lambda params: optim.AdamW(params, lr=5e-4)),\n",
        "]\n",
        "\n",
        "opt_results = []\n",
        "for name, factory in optims:\n",
        "    model = DeepFFNN(INPUT_DIM, best_deep['pattern'], NUM_CLASSES).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = factory(model.parameters())\n",
        "    es = EarlyStopper(patience=8, mode='min')\n",
        "    tr_losses, va_losses = [], []\n",
        "    start = time.time()\n",
        "    for ep in range(50):\n",
        "        tr = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "        va, _, _ = evaluate(model, val_loader, criterion)\n",
        "        tr_losses.append(tr); va_losses.append(va)\n",
        "        if es.step(va):\n",
        "            break\n",
        "    elapsed = time.time()-start\n",
        "    va_loss_o, va_preds_o, va_tgts_o = evaluate(model, val_loader, criterion)\n",
        "    opt_results.append((name, va_loss_o, elapsed))\n",
        "    # Use the global FIG_DIR for saving optimizer plots\n",
        "    plot_losses(tr_losses, va_losses, f\"opt_{name}\", save_path=FIG_DIR/f\"opt_{name}_loss.png\")\n",
        "\n",
        "print(\"Optimizer comparison (name, val_loss, time_s):\", [(n, round(l,4), round(t,1)) for n,l,t in opt_results])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ok6n30zbHTK"
      },
      "source": [
        "## Task 6 — Overfitting and Regularization\n",
        "- Build 6-layer FFNN with widths [256, 128, 64, 32, 16] (the final layer is num_classes)\n",
        "- Train with ReLU, AdamW lr=5e-4, batch=128, epochs=50\n",
        "- Inspect losses for signs of overfitting\n",
        "- Add Dropout and BatchNorm variants; try weight decay (AdamW) and compare validation/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QhMq3babHTK"
      },
      "outputs": [],
      "source": [
        "class RegFFNN(nn.Module):\n",
        "    def __init__(self, input_dim, widths, num_classes, dropout=0.0, batchnorm=False):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for w in widths:\n",
        "            layers.append(nn.Linear(prev, w))\n",
        "            if batchnorm:\n",
        "                layers.append(nn.BatchNorm1d(w))\n",
        "            layers.append(nn.ReLU())\n",
        "            if dropout > 0:\n",
        "                layers.append(nn.Dropout(dropout))\n",
        "            prev = w\n",
        "        layers.append(nn.Linear(prev, num_classes))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Baseline (no regularization)\n",
        "widths6 = [256,128,64,32,16]\n",
        "BATCH_SIZE = 128\n",
        "train_loader6 = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader6   = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "model6 = RegFFNN(INPUT_DIM, widths6, NUM_CLASSES, dropout=0.0, batchnorm=False)\n",
        "model6, tr6, va6 = train_model(model6, train_loader6, val_loader6, epochs=50, lr=5e-4, patience=8, tag=\"reg_L6_base\")\n",
        "va_loss6, va_preds6, va_tgts6 = evaluate(model6, val_loader6, nn.CrossEntropyLoss())\n",
        "print(\"Validation (no regularization):\")\n",
        "print(classification_report(va_tgts6, va_preds6, target_names=classes))\n",
        "\n",
        "# Dropout + BatchNorm + weight decay variants\n",
        "for dp in [0.2, 0.5]:\n",
        "    for bn in [False, True]:\n",
        "        tag = f\"reg_L6_dp{dp}_bn{int(bn)}\"\n",
        "        m = RegFFNN(INPUT_DIM, widths6, NUM_CLASSES, dropout=dp, batchnorm=bn).to(device)\n",
        "        weight_decay = 1e-4 if bn else 5e-4\n",
        "        # Custom train loop to set weight decay\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.AdamW(m.parameters(), lr=5e-4, weight_decay=weight_decay)\n",
        "        es = EarlyStopper(patience=8, mode='min')\n",
        "        tr_losses, va_losses = [], []\n",
        "        for ep in range(50):\n",
        "            tr = train_one_epoch(m, train_loader6, criterion, optimizer)\n",
        "            va, _, _ = evaluate(m, val_loader6, criterion)\n",
        "            tr_losses.append(tr); va_losses.append(va)\n",
        "            if es.step(va):\n",
        "                break\n",
        "        # Use the global FIG_DIR for saving regularization plots\n",
        "        plot_losses(tr_losses, va_losses, tag, save_path=FIG_DIR/f\"{tag}_loss.png\")\n",
        "        vLoss, vp, vt = evaluate(m, val_loader6, criterion)\n",
        "        print(f\"Variant {tag} — val_loss={vLoss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7gYhz6vbHTK"
      },
      "outputs": [],
      "source": [
        "class ShallowFFNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes, activation='linear'):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc_out = nn.Linear(hidden_dim, num_classes)\n",
        "        self.activation = activation\n",
        "        if activation == 'relu':\n",
        "            self.act = nn.ReLU()\n",
        "        else:\n",
        "            self.act = nn.Identity()\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.fc1(x))\n",
        "        return self.fc_out(x)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=100, lr=5e-4, weight=None, patience=10, tag=\"model\"):\n",
        "    model = model.to(device)\n",
        "    weight_t = torch.tensor(weight, dtype=torch.float32, device=device) if weight is not None else None\n",
        "    criterion = nn.CrossEntropyLoss(weight=weight_t)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "    es = EarlyStopper(patience=patience, mode='min')\n",
        "\n",
        "    tr_losses, va_losses = [] , []\n",
        "    best_state, best_va = None, float('inf')\n",
        "\n",
        "    # Assuming FIG_DIR is defined elsewhere, create it if not\n",
        "    global FIG_DIR # Access the global variable\n",
        "    if 'FIG_DIR' not in globals():\n",
        "         FIG_DIR = Path(results_path) / 'figures' # Or wherever you want to save\n",
        "         os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        tr = train_one_epoch(model, train_loader, criterion, optimizer)\n",
        "        va, _, _ = evaluate(model, val_loader, criterion)\n",
        "        tr_losses.append(tr)\n",
        "        va_losses.append(va)\n",
        "        if va < best_va:\n",
        "            best_va = va\n",
        "            best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
        "        if es.step(va):\n",
        "            break\n",
        "    # restore best\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "    # plot\n",
        "    plot_losses(tr_losses, va_losses, f\"{tag} losses\", save_path=FIG_DIR/f\"{tag}_loss.png\")\n",
        "    return model, tr_losses, va_losses\n",
        "\n",
        "# Train three widths with linear activation\n",
        "hidden_sizes = [32, 64, 128]\n",
        "results = []\n",
        "for h in hidden_sizes:\n",
        "    tag = f\"shallow_linear_h{h}\"\n",
        "    m = ShallowFFNN(INPUT_DIM, h, NUM_CLASSES, activation='linear')\n",
        "    m, tr, va = train_model(m, train_loader, val_loader, epochs=100, lr=5e-4, patience=10, tag=tag)\n",
        "    va_loss, va_preds, va_tgts = evaluate(m, val_loader, nn.CrossEntropyLoss())\n",
        "    rep = classification_report(va_tgts, va_preds, target_names=classes, output_dict=True)\n",
        "    results.append({\"h\":h, \"val_loss\":va_loss, \"report\":rep, \"model\":m})\n",
        "    # save report\n",
        "    with open(METRICS_DIR/f\"{tag}_val_report.json\", \"w\") as f:\n",
        "        json.dump(rep, f, indent=2)\n",
        "\n",
        "# Select best by lowest val loss\n",
        "best = min(results, key=lambda r: r[\"val_loss\"])\n",
        "print(\"Best width (linear):\", best[\"h\"], \"val_loss:\", best[\"val_loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuVDciWEbHTK"
      },
      "outputs": [],
      "source": [
        "# Validation reports for the 3 linear models (summary)\n",
        "for r in results:\n",
        "    h = r['h']\n",
        "    rep = r['report']\n",
        "    print(f\"\\nWidth {h} — Val loss: {r['val_loss']:.4f}\")\n",
        "    # Compact summary per class + macro/weighted\n",
        "    keys = list(classes) + ['macro avg','weighted avg','accuracy']\n",
        "    compact = {}\n",
        "    for k in keys:\n",
        "        if k in rep:\n",
        "            if k == 'accuracy':\n",
        "                compact[k] = round(rep[k], 4)\n",
        "            else:\n",
        "                compact[k] = {m: round(rep[k][m], 4) for m in ['precision','recall','f1-score'] if m in rep[k]}\n",
        "    print(compact)\n",
        "\n",
        "# Test evaluation for best linear model\n",
        "best_model = best['model']\n",
        "test_loss, test_preds, test_tgts = evaluate(best_model, test_loader, nn.CrossEntropyLoss())\n",
        "print(\"\\nTest loss (best linear):\", round(test_loss, 4))\n",
        "print(\"Validation vs Test — compare metrics (test shown below)\")\n",
        "print(classification_report(test_tgts, test_preds, target_names=classes))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_QJSBi_iRPxw",
        "4hIyPgwBbHTI",
        "YZQQDEOsbHTI",
        "_wYU39f7bHTJ",
        "W5vpgTO5bHTJ",
        "o8lrIiG6bHTK",
        "9Ok6n30zbHTK"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}